{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Scenario:\n",
    "In this project we have a dataset containing stock prices of Google from January-2012 to December-2016. We are required to use these stock prices for training the neural network and predict the stock prices for the month of January-2017. This is a Regression problem.\n",
    "\n",
    "To achieve this goal, we will train a **Recurrent Neural Network (LSTM)**. We will use one of the deep learning libraries, **Keras**, to build the neural network.\n",
    "\n",
    "\n",
    "## Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#This is a magic command. It will display the plotting image directly below the code cell\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/3/2012</td>\n",
       "      <td>325.25</td>\n",
       "      <td>332.83</td>\n",
       "      <td>324.97</td>\n",
       "      <td>663.59</td>\n",
       "      <td>7,380,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/4/2012</td>\n",
       "      <td>331.27</td>\n",
       "      <td>333.87</td>\n",
       "      <td>329.08</td>\n",
       "      <td>666.45</td>\n",
       "      <td>5,749,400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/5/2012</td>\n",
       "      <td>329.83</td>\n",
       "      <td>330.75</td>\n",
       "      <td>326.89</td>\n",
       "      <td>657.21</td>\n",
       "      <td>6,590,300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/6/2012</td>\n",
       "      <td>328.34</td>\n",
       "      <td>328.77</td>\n",
       "      <td>323.68</td>\n",
       "      <td>648.24</td>\n",
       "      <td>5,405,900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/9/2012</td>\n",
       "      <td>322.04</td>\n",
       "      <td>322.29</td>\n",
       "      <td>309.46</td>\n",
       "      <td>620.76</td>\n",
       "      <td>11,688,800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date    Open    High     Low   Close      Volume\n",
       "0  1/3/2012  325.25  332.83  324.97  663.59   7,380,500\n",
       "1  1/4/2012  331.27  333.87  329.08  666.45   5,749,400\n",
       "2  1/5/2012  329.83  330.75  326.89  657.21   6,590,300\n",
       "3  1/6/2012  328.34  328.77  323.68  648.24   5,405,900\n",
       "4  1/9/2012  322.04  322.29  309.46  620.76  11,688,800"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train_path = os.getcwd() + \"Dataset/Google_Stock_Price_Train.csv\"\n",
    "dataset_train = pd.read_csv(dataset_train_path)\n",
    "dataset_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains various information like displayed above. But in this project we will only use the \"Open\" stock prices for training our model. Therefore for the purpose of convenience we will create another variable that stores only the required (\"Open\" stock price) information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[325.25]\n",
      " [331.27]\n",
      " [329.83]\n",
      " ...\n",
      " [793.7 ]\n",
      " [783.33]\n",
      " [782.75]]\n",
      "********************\n",
      "(1258, 1)\n"
     ]
    }
   ],
   "source": [
    "training_set = dataset_train.iloc[:,1:2].values\n",
    "\n",
    "print(training_set)\n",
    "print(\"********************\")\n",
    "print(training_set.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see that there is only one column with the Open stock prices. There are a total of 1258 stock prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------#\n",
    "# Additional Information (Things to Remember!) #\n",
    "#----------------------------------------------#\n",
    "\n",
    "print(type(dataset_train))\n",
    "print(type(dataset_train.iloc[:,1:2]))   \n",
    "print(type(dataset_train.iloc[:,1:2].values))\n",
    "\n",
    "# iloc[rangeofRows, rangeofColumns]\n",
    "# Indexing starts from zero.\n",
    "# \":\" indicates entire range.\n",
    "# \"1:2\" indicates column one only. Because, the upper bound will be excluded. \n",
    "# mathematical operation are performed on the arrays. So, it is crusial to convert the data to arrays.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature scaling\n",
    "\n",
    "The performance of the neural network will be better if the entire training input is in the same range. As we can see from above the stock prices are not in the same range. So, we need to scale the training data such that they are in the same range. This process is called Feature Scaling. The two popular methods for feature scaling are:\n",
    "\n",
    "* **Standardization**\n",
    "\n",
    "$ x' = \\frac{x - \\bar{x}}{\\sigma} $\n",
    "\n",
    "where $ x $ is the original feature vector, $ \\bar{x} $ is the mean of that feature vector, and $ \\sigma $ is its standard deviation.\n",
    "\n",
    "* **Normalization** (Min-Max normalization)\n",
    "\n",
    "$ x' = \\frac{x - \\text{min}(x)}{\\text{max}(x)-\\text{min}(x)} $\n",
    "\n",
    "where $ x $ is an original value, $ x' $ is the normalized value.\n",
    "\n",
    "It is recommended to use Normalization in the case of RNN networks. Therefore we use Min-Max normalization here. You may also experiment with different feature scaling methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08581368],\n",
       "       [0.09701243],\n",
       "       [0.09433366],\n",
       "       ...,\n",
       "       [0.95725128],\n",
       "       [0.93796041],\n",
       "       [0.93688146]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range = (0,1)) \n",
    "scaled_training_set = scaler.fit_transform(training_set)\n",
    "\n",
    "scaled_training_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fit method only calculates the min and max values. It does not apply the formula on the training set. The fit_transform method applies the minmax formula on the training set. After applying the minmax formula, the transformed values will be in the range 0 and 1 i.e, the training data (features) will be in the range 0 and 1 (as shown above).\n",
    "\n",
    "## Create new Data Structure\n",
    "\n",
    "We will create a new data structure with 60 timesteps and 1 output. This means that the neural network will take in 60 inputs and produce one output. In our project, 60 stock prices i.e, stock prices corresponding to 3 previous months will be used to make the prediction. For example, the stock prices of Jan-12, Feb-12 and Mar-12 will be used to predict the stock price of the first day of Apr-12. In our training set there are 1258 stock prices:\n",
    "\n",
    "    Stock Prices(Input)   Stock Price(Output)\n",
    "    (X_train)               (y_train)\n",
    "    -----------------------------------------\n",
    "    1 to 60                  61\n",
    "    2 to 61                  62\n",
    "    3 to 62                  63\n",
    "    ......                   ...\n",
    "    1197 to 1257             1258\n",
    "\n",
    "In the next section we will create X_train and y_train data structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(60,1258):\n",
    "    X_train.append(scaled_training_set[i-60:i, 0])\n",
    "    y_train.append(scaled_training_set[i, 0])\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1198, 60)\n",
      "(1198,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping\n",
    "\n",
    "The input shape of the LSTM is 3D tensor with shape (batch_size, timesteps, input_dim). Batch_size represents the number of iterations required to traverse through the entire training data. Timesteps represent the number of inputs required for each prediction. In our scenario it is 60."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1198, 60, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.reshape(X_train,(X_train.shape[0], X_train.shape[1], 1))\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------#\n",
    "#  Initialization and Adding layers to RNN   #\n",
    "#--------------------------------------------#\n",
    "regressor = Sequential()\n",
    "\n",
    "regressor.add(LSTM(units = 50, return_sequences= True, input_shape = (X_train.shape[1], 1)))   # the first LSTM layer\n",
    "regressor.add(Dropout(0.2))                     \n",
    "\n",
    "regressor.add(LSTM(units = 50, return_sequences= True))  # the second LSTM layer\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(LSTM(units = 50, return_sequences= True))  # the third LSTM layer\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(LSTM(units = 50))  # the fourth LSTM layer\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(Dense(units=1))   # the dense layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If no activation function is specified in the dense layer then the linear activation is performed by default wherein, the dense layer takes a weighted sum of its inputs which corresponds to the predicted output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1198/1198 [==============================] - 8s 7ms/step - loss: 0.0659\n",
      "Epoch 2/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0070\n",
      "Epoch 3/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0057\n",
      "Epoch 4/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0050\n",
      "Epoch 5/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0054\n",
      "Epoch 6/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0044\n",
      "Epoch 7/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0044\n",
      "Epoch 8/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0043\n",
      "Epoch 9/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0048\n",
      "Epoch 10/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0045\n",
      "Epoch 11/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0040\n",
      "Epoch 12/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0044\n",
      "Epoch 13/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0041\n",
      "Epoch 14/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0043\n",
      "Epoch 15/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0040\n",
      "Epoch 16/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0037\n",
      "Epoch 17/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0036\n",
      "Epoch 18/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0036\n",
      "Epoch 19/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0034\n",
      "Epoch 20/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0036\n",
      "Epoch 21/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0033\n",
      "Epoch 22/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0034\n",
      "Epoch 23/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0038\n",
      "Epoch 24/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0032\n",
      "Epoch 25/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0032\n",
      "Epoch 26/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0031\n",
      "Epoch 27/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0033\n",
      "Epoch 28/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0031\n",
      "Epoch 29/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0030\n",
      "Epoch 30/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0033\n",
      "Epoch 31/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0035\n",
      "Epoch 32/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0028\n",
      "Epoch 33/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0027\n",
      "Epoch 34/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0032\n",
      "Epoch 35/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0029\n",
      "Epoch 36/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0033\n",
      "Epoch 37/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0027\n",
      "Epoch 38/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0032\n",
      "Epoch 39/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0030\n",
      "Epoch 40/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0026\n",
      "Epoch 41/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0025\n",
      "Epoch 42/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0026\n",
      "Epoch 43/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0025\n",
      "Epoch 44/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0024\n",
      "Epoch 45/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0024\n",
      "Epoch 46/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0026\n",
      "Epoch 47/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0026\n",
      "Epoch 48/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0025\n",
      "Epoch 49/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0023\n",
      "Epoch 50/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0023\n",
      "Epoch 51/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0026\n",
      "Epoch 52/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0023\n",
      "Epoch 53/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0023\n",
      "Epoch 54/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0023\n",
      "Epoch 55/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0024\n",
      "Epoch 56/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0023\n",
      "Epoch 57/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0021\n",
      "Epoch 58/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0022\n",
      "Epoch 59/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0023\n",
      "Epoch 60/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0025\n",
      "Epoch 61/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0022\n",
      "Epoch 62/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0020\n",
      "Epoch 63/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0021\n",
      "Epoch 64/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0022\n",
      "Epoch 65/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0021\n",
      "Epoch 66/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0020\n",
      "Epoch 67/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0022\n",
      "Epoch 68/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0021\n",
      "Epoch 69/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0020\n",
      "Epoch 70/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0019\n",
      "Epoch 71/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0017\n",
      "Epoch 72/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0018\n",
      "Epoch 73/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0018\n",
      "Epoch 74/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0019\n",
      "Epoch 75/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0019\n",
      "Epoch 76/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0017\n",
      "Epoch 77/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0017\n",
      "Epoch 78/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0018\n",
      "Epoch 79/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0019\n",
      "Epoch 80/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0019\n",
      "Epoch 81/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0016\n",
      "Epoch 82/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0018\n",
      "Epoch 83/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0018\n",
      "Epoch 84/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0018\n",
      "Epoch 85/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0016\n",
      "Epoch 86/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0015\n",
      "Epoch 87/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0017\n",
      "Epoch 88/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0018\n",
      "Epoch 89/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0016\n",
      "Epoch 90/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0016\n",
      "Epoch 91/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0017\n",
      "Epoch 92/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0016\n",
      "Epoch 93/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0015\n",
      "Epoch 94/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0014\n",
      "Epoch 95/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0015\n",
      "Epoch 96/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0016\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0014\n",
      "Epoch 98/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0015\n",
      "Epoch 99/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0015\n",
      "Epoch 100/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9c803da0b8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-----------------------------------------------------#\n",
    "#  Compiling and Fitting the RNN to the Training set  #\n",
    "#-----------------------------------------------------#\n",
    "\n",
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error') \n",
    "regressor.fit(X_train, y_train, epochs=100, batch_size=32)\n",
    "\n",
    "# the loss function \"mean_squared_error\"(MSE) is used because it is a Regression problem.\n",
    "# epochs = no of iterations. After every 32 (batch_size) datasets, the MSE will be calculated and \n",
    "# the tweaks will be Back Propagated i.e., the weights will be tweaked for every 32 training datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can experiment with various optimizers: https://keras.io/optimizers/ \n",
    "\n",
    "\n",
    "## Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the Actual Stock Prices of Jan-2017\n",
    "dataset_test_path = os.getcwd() + \"Dataset/Google_Stock_Price_Test.csv\"\n",
    "dataset_test = pd.read_csv(dataset_test_path)\n",
    "actual_stock_price = dataset_test.iloc[:,1:2].values\n",
    "\n",
    "# getting the Predicted Stock Prices of Jan-2017\n",
    "# Step1 - preparing the input for the model\n",
    "dataset_total = pd.concat((dataset_train['Open'], dataset_test['Open']), axis = 0)    # axis 0 = vertical concatination\n",
    "inputs = dataset_total[len(dataset_total)- len(dataset_test)-60:].values   # so that we can get the base index\n",
    "\n",
    "inputs = inputs.reshape(-1,1)     # before Reshaping- (80,) after Reshaping- (80,1)\n",
    "inputs = scaler.transform(inputs) # we don't need to fit because we want to use the previously calculated min & max values.\n",
    "\n",
    "X_test = []\n",
    "for i in range(60,80):\n",
    "    X_test.append(inputs[i-60:i, 0])\n",
    "X_test = np.array(X_test)\n",
    "X_test = np.reshape(X_test,(X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Step2 - prediction\n",
    "predicted_stock_price = regressor.predict(X_test)\n",
    "predicted_stock_price = scaler.inverse_transform(predicted_stock_price)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We \"tranform\" the inputs because we want to maintain the consistency w.r.t what we feed to the network. In the end we \"reverse transform\" the data for the convenience of plotting. As you can see in the next section, the actual and predicted stock prices are in the original scale and are not in the transformed state.\n",
    "\n",
    "For a detailed explaination regarding reshaping please read this post: http://anie.me/numpy-reshape-transpose-theano-dimshuffle/\n",
    "\n",
    "## Visualising the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f9c74eb60b8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(actual_stock_price, color = 'red', label = 'Actual Google Stock Price')\n",
    "plt.plot(predicted_stock_price, color = 'blue', label = 'Predicted Google Stock Price')\n",
    "plt.title('Google Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Google Stock Price')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that our model closely predicts the trend of the actual stock prices.\n",
    "\n",
    "The model can be further improved and experimented by considering the following (but not limited to):\n",
    "* training the model with more data. Eg: Here we have used 5 years of stock prices but you can train the model with 10 years of data.\n",
    "* increasing the number of timesteps.\n",
    "* adding more LSTM layers.\n",
    "* increasing the units in the LSTM layer.\n",
    "* adding some other indicators. Eg: If you have the financial instinct that the stock price of some other companies might be correlated to the one of Google, you could add this other stock price as a new indicator in the training data.\n",
    "\n",
    "P.S. These could also be computationally expensive."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
